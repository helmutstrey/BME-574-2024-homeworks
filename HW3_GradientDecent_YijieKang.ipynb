{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ecf7091-ca6c-4cb8-b9e1-f47b7c169ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/2024fall/BME574/Homework`\n"
     ]
    }
   ],
   "source": [
    "import Pkg\n",
    "Pkg.activate(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b502b1cf-6477-43e7-a6b9-bb934cfc2c8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/2024fall/BME574/Homework/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/2024fall/BME574/Homework/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "Pkg.add([\"Plots\", \"Optimization\", \"OptimizationOptimJL\", \"ForwardDiff\", \"Optim\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9186d723-7889-450f-a675-c4736b6d47a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "using Optimization, OptimizationOptimJL, OptimizationManopt\n",
    "using ForwardDiff\n",
    "using Optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "391001d9-a75d-4f4d-9cfd-a73ab11a818f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1mO\u001b[22m\u001b[0m\u001b[1mp\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mm\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mz\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1mF\u001b[22m\u001b[0m\u001b[1mu\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mn\u001b[22m Multi\u001b[0m\u001b[1mO\u001b[22mbjectiveO\u001b[0m\u001b[1mp\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mm\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mz\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1mF\u001b[22m\u001b[0m\u001b[1mu\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "struct OptimizationFunction{iip, AD, F, G, FG, H, FGH, HV, C, CJ, CJV, CVJ, CH, HP, CJP, CHP, O, EX, CEX, SYS, LH, LHP, HCV, CJCV, CHCV, LHCV} <: SciMLBase.AbstractOptimizationFunction{iip}\n",
       "\\end{verbatim}\n",
       "A representation of an objective function \\texttt{f}, defined by:\n",
       "\n",
       "$$\\min_{u} f(u,p)$$\n",
       "and all of its related functions, such as the gradient of \\texttt{f}, its Hessian, and more. For all cases, \\texttt{u} is the state which in this case are the optimization variables and \\texttt{p} are the fixed parameters or data.\n",
       "\n",
       "\\subsection{Constructor}\n",
       "\\begin{verbatim}\n",
       "OptimizationFunction{iip}(f, adtype::AbstractADType = NoAD();\n",
       "                          grad = nothing, hess = nothing, hv = nothing,\n",
       "                          cons = nothing, cons_j = nothing, cons_jvp = nothing,\n",
       "                          cons_vjp = nothing, cons_h = nothing,\n",
       "                          hess_prototype = nothing,\n",
       "                          cons_jac_prototype = nothing,\n",
       "                          cons_hess_prototype = nothing,\n",
       "                          observed = __has_observed(f) ? f.observed : DEFAULT_OBSERVED_NO_TIME,\n",
       "                          lag_h = nothing,\n",
       "                          hess_colorvec = __has_colorvec(f) ? f.colorvec : nothing,\n",
       "                          cons_jac_colorvec = __has_colorvec(f) ? f.colorvec : nothing,\n",
       "                          cons_hess_colorvec = __has_colorvec(f) ? f.colorvec : nothing,\n",
       "                          lag_hess_colorvec = nothing,\n",
       "                          sys = __has_sys(f) ? f.sys : nothing)\n",
       "\\end{verbatim}\n",
       "\\subsection{Positional Arguments}\n",
       "\\begin{itemize}\n",
       "\\item \\texttt{f(u,p)}: the function to optimize. \\texttt{u} are the optimization variables and \\texttt{p} are fixed parameters or data used in the objective, \n",
       "\n",
       "\\end{itemize}\n",
       "even if no such parameters are used in the objective it should be an argument in the function. For minibatching \\texttt{p} can be used to pass in a minibatch, take a look at the tutorial \\href{https://docs.sciml.ai/Optimization/stable/tutorials/minibatch/}{here} to see how to do it.  This should return a scalar, the loss value, as the return output.\n",
       "\n",
       "\\begin{itemize}\n",
       "\\item \\texttt{adtype}: see the Defining Optimization Functions via AD section below.\n",
       "\n",
       "\\end{itemize}\n",
       "\\subsection{Keyword Arguments}\n",
       "\\begin{itemize}\n",
       "\\item \\texttt{grad(G,u,p)} or \\texttt{G=grad(u,p)}: the gradient of \\texttt{f} with respect to \\texttt{u}.\n",
       "\n",
       "\n",
       "\\item \\texttt{hess(H,u,p)} or \\texttt{H=hess(u,p)}: the Hessian of \\texttt{f} with respect to \\texttt{u}.\n",
       "\n",
       "\n",
       "\\item \\texttt{hv(Hv,u,v,p)} or \\texttt{Hv=hv(u,v,p)}: the Hessian-vector product $(d^2 f / du^2) v$.\n",
       "\n",
       "\n",
       "\\item \\texttt{cons(res,u,p)} or \\texttt{res=cons(u,p)} : the constraints function, should mutate the passed \\texttt{res} array   with value of the \\texttt{i}th constraint, evaluated at the current values of variables   inside the optimization routine. This takes just the function evaluations   and the equality or inequality assertion is applied by the solver based on the constraint   bounds passed as \\texttt{lcons} and \\texttt{ucons} to \\href{@ref}{\\texttt{OptimizationProblem}}, in case of equality   constraints \\texttt{lcons} and \\texttt{ucons} should be passed equal values.\n",
       "\n",
       "\n",
       "\\item \\texttt{cons\\_j(J,u,p)} or \\texttt{J=cons\\_j(u,p)}: the Jacobian of the constraints.\n",
       "\n",
       "\n",
       "\\item \\texttt{cons\\_jvp(Jv,u,v,p)} or \\texttt{Jv=cons\\_jvp(u,v,p)}: the Jacobian-vector product of the constraints.\n",
       "\n",
       "\n",
       "\\item \\texttt{cons\\_vjp(Jv,u,v,p)} or \\texttt{Jv=cons\\_vjp(u,v,p)}: the Jacobian-vector product of the constraints.\n",
       "\n",
       "\n",
       "\\item \\texttt{cons\\_h(H,u,p)} or \\texttt{H=cons\\_h(u,p)}: the Hessian of the constraints, provided as  an array of Hessians with \\texttt{res[i]} being the Hessian with respect to the \\texttt{i}th output on \\texttt{cons}.\n",
       "\n",
       "\n",
       "\\item \\texttt{hess\\_prototype}: a prototype matrix matching the type that matches the Hessian. For example, if the Hessian is tridiagonal, then an appropriately sized \\texttt{Hessian} matrix can be used as the prototype and optimization solvers will specialize on this structure where possible. Non-structured sparsity patterns should use a \\texttt{SparseMatrixCSC} with a correct sparsity pattern for the Hessian. The default is \\texttt{nothing}, which means a dense Hessian.\n",
       "\n",
       "\n",
       "\\item \\texttt{cons\\_jac\\_prototype}: a prototype matrix matching the type that matches the constraint Jacobian. The default is \\texttt{nothing}, which means a dense constraint Jacobian.\n",
       "\n",
       "\n",
       "\\item \\texttt{cons\\_hess\\_prototype}: a prototype matrix matching the type that matches the constraint Hessian. This is defined as an array of matrices, where \\texttt{hess[i]} is the Hessian w.r.t. the \\texttt{i}th output. For example, if the Hessian is sparse, then \\texttt{hess} is a \\texttt{Vector\\{SparseMatrixCSC\\}}. The default is \\texttt{nothing}, which means a dense constraint Hessian.\n",
       "\n",
       "\n",
       "\\item \\texttt{lag\\_h(res,u,sigma,mu,p)} or \\texttt{res=lag\\_h(u,sigma,mu,p)}: the Hessian of the Lagrangian, where \\texttt{sigma} is a multiplier of the cost function and \\texttt{mu} are the Lagrange multipliers multiplying the constraints. This can be provided instead of \\texttt{hess} and \\texttt{cons\\_h} to solvers that directly use the Hessian of the Lagrangian.\n",
       "\n",
       "\n",
       "\\item \\texttt{hess\\_colorvec}: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the \\texttt{hess\\_prototype}. This specializes the Hessian construction when using finite differences and automatic differentiation to be computed in an accelerated manner based on the sparsity pattern. Defaults to \\texttt{nothing}, which means a color vector will be internally computed on demand when required. The cost of this operation is highly dependent on the sparsity pattern.\n",
       "\n",
       "\n",
       "\\item \\texttt{cons\\_jac\\_colorvec}: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the \\texttt{cons\\_jac\\_prototype}.\n",
       "\n",
       "\n",
       "\\item \\texttt{cons\\_hess\\_colorvec}: an array of color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the \\texttt{cons\\_hess\\_prototype}.\n",
       "\n",
       "\\end{itemize}\n",
       "When \\href{https://docs.sciml.ai/Optimization/stable/tutorials/symbolic/}{Symbolic Problem Building with ModelingToolkit} interface is used the following arguments are also relevant:\n",
       "\n",
       "\\begin{itemize}\n",
       "\\item \\texttt{observed}: an algebraic combination of optimization variables that is of interest to the user   which will be available in the solution. This can be single or multiple expressions.\n",
       "\n",
       "\n",
       "\\item \\texttt{sys}: field that stores the \\texttt{OptimizationSystem}.\n",
       "\n",
       "\\end{itemize}\n",
       "\\subsection{Defining Optimization Functions via AD}\n",
       "While using the keyword arguments gives the user control over defining all of the possible functions, the simplest way to handle the generation of an \\texttt{OptimizationFunction} is by specifying an option from ADTypes.jl which lets the user choose the Automatic Differentiation backend to use for automatically filling in all of the extra functions. For example,\n",
       "\n",
       "\\begin{verbatim}\n",
       "OptimizationFunction(f,AutoForwardDiff())\n",
       "\\end{verbatim}\n",
       "will use \\href{https://github.com/JuliaDiff/ForwardDiff.jl}{ForwardDiff.jl} to define all of the necessary functions. Note that if any functions are defined directly, the auto-AD definition does not overwrite the user's choice.\n",
       "\n",
       "Each of the AD-based constructors are documented separately via their own dispatches below in the \\href{@ref ad}{Automatic Differentiation Construction Choice Recommendations} section.\n",
       "\n",
       "\\subsection{iip: In-Place vs Out-Of-Place}\n",
       "For more details on this argument, see the ODEFunction documentation.\n",
       "\n",
       "\\subsection{specialize: Controlling Compilation and Specialization}\n",
       "For more details on this argument, see the ODEFunction documentation.\n",
       "\n",
       "\\subsection{Fields}\n",
       "The fields of the OptimizationFunction type directly match the names of the inputs.\n",
       "\n"
      ],
      "text/markdown": [
       "```julia\n",
       "struct OptimizationFunction{iip, AD, F, G, FG, H, FGH, HV, C, CJ, CJV, CVJ, CH, HP, CJP, CHP, O, EX, CEX, SYS, LH, LHP, HCV, CJCV, CHCV, LHCV} <: SciMLBase.AbstractOptimizationFunction{iip}\n",
       "```\n",
       "\n",
       "A representation of an objective function `f`, defined by:\n",
       "\n",
       "$$\n",
       "\\min_{u} f(u,p)\n",
       "$$\n",
       "\n",
       "and all of its related functions, such as the gradient of `f`, its Hessian, and more. For all cases, `u` is the state which in this case are the optimization variables and `p` are the fixed parameters or data.\n",
       "\n",
       "## Constructor\n",
       "\n",
       "```julia\n",
       "OptimizationFunction{iip}(f, adtype::AbstractADType = NoAD();\n",
       "                          grad = nothing, hess = nothing, hv = nothing,\n",
       "                          cons = nothing, cons_j = nothing, cons_jvp = nothing,\n",
       "                          cons_vjp = nothing, cons_h = nothing,\n",
       "                          hess_prototype = nothing,\n",
       "                          cons_jac_prototype = nothing,\n",
       "                          cons_hess_prototype = nothing,\n",
       "                          observed = __has_observed(f) ? f.observed : DEFAULT_OBSERVED_NO_TIME,\n",
       "                          lag_h = nothing,\n",
       "                          hess_colorvec = __has_colorvec(f) ? f.colorvec : nothing,\n",
       "                          cons_jac_colorvec = __has_colorvec(f) ? f.colorvec : nothing,\n",
       "                          cons_hess_colorvec = __has_colorvec(f) ? f.colorvec : nothing,\n",
       "                          lag_hess_colorvec = nothing,\n",
       "                          sys = __has_sys(f) ? f.sys : nothing)\n",
       "```\n",
       "\n",
       "## Positional Arguments\n",
       "\n",
       "  * `f(u,p)`: the function to optimize. `u` are the optimization variables and `p` are fixed parameters or data used in the objective,\n",
       "\n",
       "even if no such parameters are used in the objective it should be an argument in the function. For minibatching `p` can be used to pass in a minibatch, take a look at the tutorial [here](https://docs.sciml.ai/Optimization/stable/tutorials/minibatch/) to see how to do it.  This should return a scalar, the loss value, as the return output.\n",
       "\n",
       "  * `adtype`: see the Defining Optimization Functions via AD section below.\n",
       "\n",
       "## Keyword Arguments\n",
       "\n",
       "  * `grad(G,u,p)` or `G=grad(u,p)`: the gradient of `f` with respect to `u`.\n",
       "  * `hess(H,u,p)` or `H=hess(u,p)`: the Hessian of `f` with respect to `u`.\n",
       "  * `hv(Hv,u,v,p)` or `Hv=hv(u,v,p)`: the Hessian-vector product $(d^2 f / du^2) v$.\n",
       "  * `cons(res,u,p)` or `res=cons(u,p)` : the constraints function, should mutate the passed `res` array   with value of the `i`th constraint, evaluated at the current values of variables   inside the optimization routine. This takes just the function evaluations   and the equality or inequality assertion is applied by the solver based on the constraint   bounds passed as `lcons` and `ucons` to [`OptimizationProblem`](@ref), in case of equality   constraints `lcons` and `ucons` should be passed equal values.\n",
       "  * `cons_j(J,u,p)` or `J=cons_j(u,p)`: the Jacobian of the constraints.\n",
       "  * `cons_jvp(Jv,u,v,p)` or `Jv=cons_jvp(u,v,p)`: the Jacobian-vector product of the constraints.\n",
       "  * `cons_vjp(Jv,u,v,p)` or `Jv=cons_vjp(u,v,p)`: the Jacobian-vector product of the constraints.\n",
       "  * `cons_h(H,u,p)` or `H=cons_h(u,p)`: the Hessian of the constraints, provided as  an array of Hessians with `res[i]` being the Hessian with respect to the `i`th output on `cons`.\n",
       "  * `hess_prototype`: a prototype matrix matching the type that matches the Hessian. For example, if the Hessian is tridiagonal, then an appropriately sized `Hessian` matrix can be used as the prototype and optimization solvers will specialize on this structure where possible. Non-structured sparsity patterns should use a `SparseMatrixCSC` with a correct sparsity pattern for the Hessian. The default is `nothing`, which means a dense Hessian.\n",
       "  * `cons_jac_prototype`: a prototype matrix matching the type that matches the constraint Jacobian. The default is `nothing`, which means a dense constraint Jacobian.\n",
       "  * `cons_hess_prototype`: a prototype matrix matching the type that matches the constraint Hessian. This is defined as an array of matrices, where `hess[i]` is the Hessian w.r.t. the `i`th output. For example, if the Hessian is sparse, then `hess` is a `Vector{SparseMatrixCSC}`. The default is `nothing`, which means a dense constraint Hessian.\n",
       "  * `lag_h(res,u,sigma,mu,p)` or `res=lag_h(u,sigma,mu,p)`: the Hessian of the Lagrangian, where `sigma` is a multiplier of the cost function and `mu` are the Lagrange multipliers multiplying the constraints. This can be provided instead of `hess` and `cons_h` to solvers that directly use the Hessian of the Lagrangian.\n",
       "  * `hess_colorvec`: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the `hess_prototype`. This specializes the Hessian construction when using finite differences and automatic differentiation to be computed in an accelerated manner based on the sparsity pattern. Defaults to `nothing`, which means a color vector will be internally computed on demand when required. The cost of this operation is highly dependent on the sparsity pattern.\n",
       "  * `cons_jac_colorvec`: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the `cons_jac_prototype`.\n",
       "  * `cons_hess_colorvec`: an array of color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the `cons_hess_prototype`.\n",
       "\n",
       "When [Symbolic Problem Building with ModelingToolkit](https://docs.sciml.ai/Optimization/stable/tutorials/symbolic/) interface is used the following arguments are also relevant:\n",
       "\n",
       "  * `observed`: an algebraic combination of optimization variables that is of interest to the user   which will be available in the solution. This can be single or multiple expressions.\n",
       "  * `sys`: field that stores the `OptimizationSystem`.\n",
       "\n",
       "## Defining Optimization Functions via AD\n",
       "\n",
       "While using the keyword arguments gives the user control over defining all of the possible functions, the simplest way to handle the generation of an `OptimizationFunction` is by specifying an option from ADTypes.jl which lets the user choose the Automatic Differentiation backend to use for automatically filling in all of the extra functions. For example,\n",
       "\n",
       "```julia\n",
       "OptimizationFunction(f,AutoForwardDiff())\n",
       "```\n",
       "\n",
       "will use [ForwardDiff.jl](https://github.com/JuliaDiff/ForwardDiff.jl) to define all of the necessary functions. Note that if any functions are defined directly, the auto-AD definition does not overwrite the user's choice.\n",
       "\n",
       "Each of the AD-based constructors are documented separately via their own dispatches below in the [Automatic Differentiation Construction Choice Recommendations](@ref ad) section.\n",
       "\n",
       "## iip: In-Place vs Out-Of-Place\n",
       "\n",
       "For more details on this argument, see the ODEFunction documentation.\n",
       "\n",
       "## specialize: Controlling Compilation and Specialization\n",
       "\n",
       "For more details on this argument, see the ODEFunction documentation.\n",
       "\n",
       "## Fields\n",
       "\n",
       "The fields of the OptimizationFunction type directly match the names of the inputs.\n"
      ],
      "text/plain": [
       "\u001b[36m  struct OptimizationFunction{iip, AD, F, G, FG, H, FGH, HV, C, CJ, CJV, CVJ, CH, HP, CJP, CHP, O, EX, CEX, SYS, LH, LHP, HCV, CJCV, CHCV, LHCV} <: SciMLBase.AbstractOptimizationFunction{iip}\u001b[39m\n",
       "\n",
       "  A representation of an objective function \u001b[36mf\u001b[39m, defined by:\n",
       "\n",
       "\u001b[35m  \\min_{u} f(u,p)\u001b[39m\n",
       "\n",
       "  and all of its related functions, such as the gradient of \u001b[36mf\u001b[39m, its Hessian,\n",
       "  and more. For all cases, \u001b[36mu\u001b[39m is the state which in this case are the\n",
       "  optimization variables and \u001b[36mp\u001b[39m are the fixed parameters or data.\n",
       "\n",
       "\u001b[1m  Constructor\u001b[22m\n",
       "\u001b[1m  ===========\u001b[22m\n",
       "\n",
       "\u001b[36m  OptimizationFunction{iip}(f, adtype::AbstractADType = NoAD();\u001b[39m\n",
       "\u001b[36m                            grad = nothing, hess = nothing, hv = nothing,\u001b[39m\n",
       "\u001b[36m                            cons = nothing, cons_j = nothing, cons_jvp = nothing,\u001b[39m\n",
       "\u001b[36m                            cons_vjp = nothing, cons_h = nothing,\u001b[39m\n",
       "\u001b[36m                            hess_prototype = nothing,\u001b[39m\n",
       "\u001b[36m                            cons_jac_prototype = nothing,\u001b[39m\n",
       "\u001b[36m                            cons_hess_prototype = nothing,\u001b[39m\n",
       "\u001b[36m                            observed = __has_observed(f) ? f.observed : DEFAULT_OBSERVED_NO_TIME,\u001b[39m\n",
       "\u001b[36m                            lag_h = nothing,\u001b[39m\n",
       "\u001b[36m                            hess_colorvec = __has_colorvec(f) ? f.colorvec : nothing,\u001b[39m\n",
       "\u001b[36m                            cons_jac_colorvec = __has_colorvec(f) ? f.colorvec : nothing,\u001b[39m\n",
       "\u001b[36m                            cons_hess_colorvec = __has_colorvec(f) ? f.colorvec : nothing,\u001b[39m\n",
       "\u001b[36m                            lag_hess_colorvec = nothing,\u001b[39m\n",
       "\u001b[36m                            sys = __has_sys(f) ? f.sys : nothing)\u001b[39m\n",
       "\n",
       "\u001b[1m  Positional Arguments\u001b[22m\n",
       "\u001b[1m  ====================\u001b[22m\n",
       "\n",
       "    •  \u001b[36mf(u,p)\u001b[39m: the function to optimize. \u001b[36mu\u001b[39m are the optimization variables\n",
       "       and \u001b[36mp\u001b[39m are fixed parameters or data used in the objective,\n",
       "\n",
       "  even if no such parameters are used in the objective it should be an\n",
       "  argument in the function. For minibatching \u001b[36mp\u001b[39m can be used to pass in a\n",
       "  minibatch, take a look at the tutorial here\n",
       "  (https://docs.sciml.ai/Optimization/stable/tutorials/minibatch/) to see how\n",
       "  to do it. This should return a scalar, the loss value, as the return output.\n",
       "\n",
       "    •  \u001b[36madtype\u001b[39m: see the Defining Optimization Functions via AD section\n",
       "       below.\n",
       "\n",
       "\u001b[1m  Keyword Arguments\u001b[22m\n",
       "\u001b[1m  =================\u001b[22m\n",
       "\n",
       "    •  \u001b[36mgrad(G,u,p)\u001b[39m or \u001b[36mG=grad(u,p)\u001b[39m: the gradient of \u001b[36mf\u001b[39m with respect to \u001b[36mu\u001b[39m.\n",
       "\n",
       "    •  \u001b[36mhess(H,u,p)\u001b[39m or \u001b[36mH=hess(u,p)\u001b[39m: the Hessian of \u001b[36mf\u001b[39m with respect to \u001b[36mu\u001b[39m.\n",
       "\n",
       "    •  \u001b[36mhv(Hv,u,v,p)\u001b[39m or \u001b[36mHv=hv(u,v,p)\u001b[39m: the Hessian-vector product \u001b[35m(d^2 f /\n",
       "       du^2) v\u001b[39m.\n",
       "\n",
       "    •  \u001b[36mcons(res,u,p)\u001b[39m or \u001b[36mres=cons(u,p)\u001b[39m : the constraints function, should\n",
       "       mutate the passed \u001b[36mres\u001b[39m array with value of the \u001b[36mi\u001b[39mth constraint,\n",
       "       evaluated at the current values of variables inside the\n",
       "       optimization routine. This takes just the function evaluations and\n",
       "       the equality or inequality assertion is applied by the solver\n",
       "       based on the constraint bounds passed as \u001b[36mlcons\u001b[39m and \u001b[36mucons\u001b[39m to\n",
       "       \u001b[36mOptimizationProblem\u001b[39m, in case of equality constraints \u001b[36mlcons\u001b[39m and\n",
       "       \u001b[36mucons\u001b[39m should be passed equal values.\n",
       "\n",
       "    •  \u001b[36mcons_j(J,u,p)\u001b[39m or \u001b[36mJ=cons_j(u,p)\u001b[39m: the Jacobian of the constraints.\n",
       "\n",
       "    •  \u001b[36mcons_jvp(Jv,u,v,p)\u001b[39m or \u001b[36mJv=cons_jvp(u,v,p)\u001b[39m: the Jacobian-vector\n",
       "       product of the constraints.\n",
       "\n",
       "    •  \u001b[36mcons_vjp(Jv,u,v,p)\u001b[39m or \u001b[36mJv=cons_vjp(u,v,p)\u001b[39m: the Jacobian-vector\n",
       "       product of the constraints.\n",
       "\n",
       "    •  \u001b[36mcons_h(H,u,p)\u001b[39m or \u001b[36mH=cons_h(u,p)\u001b[39m: the Hessian of the constraints,\n",
       "       provided as an array of Hessians with \u001b[36mres[i]\u001b[39m being the Hessian\n",
       "       with respect to the \u001b[36mi\u001b[39mth output on \u001b[36mcons\u001b[39m.\n",
       "\n",
       "    •  \u001b[36mhess_prototype\u001b[39m: a prototype matrix matching the type that matches\n",
       "       the Hessian. For example, if the Hessian is tridiagonal, then an\n",
       "       appropriately sized \u001b[36mHessian\u001b[39m matrix can be used as the prototype\n",
       "       and optimization solvers will specialize on this structure where\n",
       "       possible. Non-structured sparsity patterns should use a\n",
       "       \u001b[36mSparseMatrixCSC\u001b[39m with a correct sparsity pattern for the Hessian.\n",
       "       The default is \u001b[36mnothing\u001b[39m, which means a dense Hessian.\n",
       "\n",
       "    •  \u001b[36mcons_jac_prototype\u001b[39m: a prototype matrix matching the type that\n",
       "       matches the constraint Jacobian. The default is \u001b[36mnothing\u001b[39m, which\n",
       "       means a dense constraint Jacobian.\n",
       "\n",
       "    •  \u001b[36mcons_hess_prototype\u001b[39m: a prototype matrix matching the type that\n",
       "       matches the constraint Hessian. This is defined as an array of\n",
       "       matrices, where \u001b[36mhess[i]\u001b[39m is the Hessian w.r.t. the \u001b[36mi\u001b[39mth output. For\n",
       "       example, if the Hessian is sparse, then \u001b[36mhess\u001b[39m is a\n",
       "       \u001b[36mVector{SparseMatrixCSC}\u001b[39m. The default is \u001b[36mnothing\u001b[39m, which means a\n",
       "       dense constraint Hessian.\n",
       "\n",
       "    •  \u001b[36mlag_h(res,u,sigma,mu,p)\u001b[39m or \u001b[36mres=lag_h(u,sigma,mu,p)\u001b[39m: the Hessian of\n",
       "       the Lagrangian, where \u001b[36msigma\u001b[39m is a multiplier of the cost function\n",
       "       and \u001b[36mmu\u001b[39m are the Lagrange multipliers multiplying the constraints.\n",
       "       This can be provided instead of \u001b[36mhess\u001b[39m and \u001b[36mcons_h\u001b[39m to solvers that\n",
       "       directly use the Hessian of the Lagrangian.\n",
       "\n",
       "    •  \u001b[36mhess_colorvec\u001b[39m: a color vector according to the SparseDiffTools.jl\n",
       "       definition for the sparsity pattern of the \u001b[36mhess_prototype\u001b[39m. This\n",
       "       specializes the Hessian construction when using finite differences\n",
       "       and automatic differentiation to be computed in an accelerated\n",
       "       manner based on the sparsity pattern. Defaults to \u001b[36mnothing\u001b[39m, which\n",
       "       means a color vector will be internally computed on demand when\n",
       "       required. The cost of this operation is highly dependent on the\n",
       "       sparsity pattern.\n",
       "\n",
       "    •  \u001b[36mcons_jac_colorvec\u001b[39m: a color vector according to the\n",
       "       SparseDiffTools.jl definition for the sparsity pattern of the\n",
       "       \u001b[36mcons_jac_prototype\u001b[39m.\n",
       "\n",
       "    •  \u001b[36mcons_hess_colorvec\u001b[39m: an array of color vector according to the\n",
       "       SparseDiffTools.jl definition for the sparsity pattern of the\n",
       "       \u001b[36mcons_hess_prototype\u001b[39m.\n",
       "\n",
       "  When Symbolic Problem Building with ModelingToolkit\n",
       "  (https://docs.sciml.ai/Optimization/stable/tutorials/symbolic/) interface is\n",
       "  used the following arguments are also relevant:\n",
       "\n",
       "    •  \u001b[36mobserved\u001b[39m: an algebraic combination of optimization variables that\n",
       "       is of interest to the user which will be available in the\n",
       "       solution. This can be single or multiple expressions.\n",
       "\n",
       "    •  \u001b[36msys\u001b[39m: field that stores the \u001b[36mOptimizationSystem\u001b[39m.\n",
       "\n",
       "\u001b[1m  Defining Optimization Functions via AD\u001b[22m\n",
       "\u001b[1m  ======================================\u001b[22m\n",
       "\n",
       "  While using the keyword arguments gives the user control over defining all\n",
       "  of the possible functions, the simplest way to handle the generation of an\n",
       "  \u001b[36mOptimizationFunction\u001b[39m is by specifying an option from ADTypes.jl which lets\n",
       "  the user choose the Automatic Differentiation backend to use for\n",
       "  automatically filling in all of the extra functions. For example,\n",
       "\n",
       "\u001b[36m  OptimizationFunction(f,AutoForwardDiff())\u001b[39m\n",
       "\n",
       "  will use ForwardDiff.jl (https://github.com/JuliaDiff/ForwardDiff.jl) to\n",
       "  define all of the necessary functions. Note that if any functions are\n",
       "  defined directly, the auto-AD definition does not overwrite the user's\n",
       "  choice.\n",
       "\n",
       "  Each of the AD-based constructors are documented separately via their own\n",
       "  dispatches below in the Automatic Differentiation Construction Choice\n",
       "  Recommendations section.\n",
       "\n",
       "\u001b[1m  iip: In-Place vs Out-Of-Place\u001b[22m\n",
       "\u001b[1m  =============================\u001b[22m\n",
       "\n",
       "  For more details on this argument, see the ODEFunction documentation.\n",
       "\n",
       "\u001b[1m  specialize: Controlling Compilation and Specialization\u001b[22m\n",
       "\u001b[1m  ======================================================\u001b[22m\n",
       "\n",
       "  For more details on this argument, see the ODEFunction documentation.\n",
       "\n",
       "\u001b[1m  Fields\u001b[22m\n",
       "\u001b[1m  ======\u001b[22m\n",
       "\n",
       "  The fields of the OptimizationFunction type directly match the names of the\n",
       "  inputs."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?OptimizationFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23794f1e-305b-4bb8-bf93-6e76002a1985",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1mA\u001b[22m\u001b[0m\u001b[1mu\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mF\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1mw\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1md\u001b[22m\u001b[0m\u001b[1mD\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mf\u001b[22m\u001b[0m\u001b[1mf\u001b[22m \u001b[0m\u001b[1mA\u001b[22m\u001b[0m\u001b[1mu\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1mo\u001b[22mSparse\u001b[0m\u001b[1mF\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1mw\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1md\u001b[22m\u001b[0m\u001b[1mD\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mf\u001b[22m\u001b[0m\u001b[1mf\u001b[22m \u001b[0m\u001b[1mA\u001b[22m\u001b[0m\u001b[1mu\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1mo\u001b[22mPolyester\u001b[0m\u001b[1mF\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1mw\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1md\u001b[22m\u001b[0m\u001b[1mD\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1mf\u001b[22m\u001b[0m\u001b[1mf\u001b[22m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "AutoForwardDiff{chunksize,T}\n",
       "\\end{verbatim}\n",
       "Struct used to select the \\href{https://github.com/JuliaDiff/ForwardDiff.jl}{ForwardDiff.jl} backend for automatic differentiation.\n",
       "\n",
       "Defined by \\href{https://github.com/SciML/ADTypes.jl}{ADTypes.jl}.\n",
       "\n",
       "\\section{Constructors}\n",
       "\\begin{verbatim}\n",
       "AutoForwardDiff(; chunksize=nothing, tag=nothing)\n",
       "\\end{verbatim}\n",
       "\\section{Type parameters}\n",
       "\\begin{itemize}\n",
       "\\item \\texttt{chunksize}: the preferred \\href{https://juliadiff.org/ForwardDiff.jl/stable/user/advanced/#Configuring-Chunk-Size}{chunk size} to evaluate several derivatives at once\n",
       "\n",
       "\\end{itemize}\n",
       "\\section{Fields}\n",
       "\\begin{itemize}\n",
       "\\item \\texttt{tag::T}: a \\href{https://juliadiff.org/ForwardDiff.jl/release-0.10/user/advanced.html#Custom-tags-and-tag-checking-1}{custom tag} to handle nested differentiation calls (usually not necessary)\n",
       "\n",
       "\\end{itemize}\n",
       "\\rule{\\textwidth}{1pt}\n",
       "\\begin{verbatim}\n",
       "AutoForwardDiff{chunksize} <: AbstractADType\n",
       "\\end{verbatim}\n",
       "An AbstractADType choice for use in OptimizationFunction for automatically generating the unspecified derivative functions. Usage:\n",
       "\n",
       "\\begin{verbatim}\n",
       "OptimizationFunction(f, AutoForwardDiff(); kwargs...)\n",
       "\\end{verbatim}\n",
       "This uses the \\href{https://github.com/JuliaDiff/ForwardDiff.jl}{ForwardDiff.jl} package. It is the fastest choice for small systems, especially with heavy scalar interactions. It is easy to use and compatible with most Julia functions which have loose type restrictions. However, because it's forward-mode, it scales poorly in comparison to other AD choices. Hessian construction is suboptimal as it uses the forward-over-forward approach.\n",
       "\n",
       "\\begin{itemize}\n",
       "\\item Compatible with GPUs\n",
       "\n",
       "\n",
       "\\item Compatible with Hessian-based optimization\n",
       "\n",
       "\n",
       "\\item Compatible with Hv-based optimization\n",
       "\n",
       "\n",
       "\\item Compatible with constraints\n",
       "\n",
       "\\end{itemize}\n",
       "Note that only the unspecified derivative functions are defined. For example, if a \\texttt{hess} function is supplied to the \\texttt{OptimizationFunction}, then the Hessian is not defined via ForwardDiff.\n",
       "\n"
      ],
      "text/markdown": [
       "```\n",
       "AutoForwardDiff{chunksize,T}\n",
       "```\n",
       "\n",
       "Struct used to select the [ForwardDiff.jl](https://github.com/JuliaDiff/ForwardDiff.jl) backend for automatic differentiation.\n",
       "\n",
       "Defined by [ADTypes.jl](https://github.com/SciML/ADTypes.jl).\n",
       "\n",
       "# Constructors\n",
       "\n",
       "```\n",
       "AutoForwardDiff(; chunksize=nothing, tag=nothing)\n",
       "```\n",
       "\n",
       "# Type parameters\n",
       "\n",
       "  * `chunksize`: the preferred [chunk size](https://juliadiff.org/ForwardDiff.jl/stable/user/advanced/#Configuring-Chunk-Size) to evaluate several derivatives at once\n",
       "\n",
       "# Fields\n",
       "\n",
       "  * `tag::T`: a [custom tag](https://juliadiff.org/ForwardDiff.jl/release-0.10/user/advanced.html#Custom-tags-and-tag-checking-1) to handle nested differentiation calls (usually not necessary)\n",
       "\n",
       "---\n",
       "\n",
       "```\n",
       "AutoForwardDiff{chunksize} <: AbstractADType\n",
       "```\n",
       "\n",
       "An AbstractADType choice for use in OptimizationFunction for automatically generating the unspecified derivative functions. Usage:\n",
       "\n",
       "```julia\n",
       "OptimizationFunction(f, AutoForwardDiff(); kwargs...)\n",
       "```\n",
       "\n",
       "This uses the [ForwardDiff.jl](https://github.com/JuliaDiff/ForwardDiff.jl) package. It is the fastest choice for small systems, especially with heavy scalar interactions. It is easy to use and compatible with most Julia functions which have loose type restrictions. However, because it's forward-mode, it scales poorly in comparison to other AD choices. Hessian construction is suboptimal as it uses the forward-over-forward approach.\n",
       "\n",
       "  * Compatible with GPUs\n",
       "  * Compatible with Hessian-based optimization\n",
       "  * Compatible with Hv-based optimization\n",
       "  * Compatible with constraints\n",
       "\n",
       "Note that only the unspecified derivative functions are defined. For example, if a `hess` function is supplied to the `OptimizationFunction`, then the Hessian is not defined via ForwardDiff.\n"
      ],
      "text/plain": [
       "\u001b[36m  AutoForwardDiff{chunksize,T}\u001b[39m\n",
       "\n",
       "  Struct used to select the ForwardDiff.jl\n",
       "  (https://github.com/JuliaDiff/ForwardDiff.jl) backend for automatic\n",
       "  differentiation.\n",
       "\n",
       "  Defined by ADTypes.jl (https://github.com/SciML/ADTypes.jl).\n",
       "\n",
       "\u001b[1m  Constructors\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "\u001b[36m  AutoForwardDiff(; chunksize=nothing, tag=nothing)\u001b[39m\n",
       "\n",
       "\u001b[1m  Type parameters\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "    •  \u001b[36mchunksize\u001b[39m: the preferred chunk size\n",
       "       (https://juliadiff.org/ForwardDiff.jl/stable/user/advanced/#Configuring-Chunk-Size)\n",
       "       to evaluate several derivatives at once\n",
       "\n",
       "\u001b[1m  Fields\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "    •  \u001b[36mtag::T\u001b[39m: a custom tag\n",
       "       (https://juliadiff.org/ForwardDiff.jl/release-0.10/user/advanced.html#Custom-tags-and-tag-checking-1)\n",
       "       to handle nested differentiation calls (usually not necessary)\n",
       "\n",
       "  ────────────────────────────────────────────────────────────────────────────\n",
       "\n",
       "\u001b[36m  AutoForwardDiff{chunksize} <: AbstractADType\u001b[39m\n",
       "\n",
       "  An AbstractADType choice for use in OptimizationFunction for automatically\n",
       "  generating the unspecified derivative functions. Usage:\n",
       "\n",
       "\u001b[36m  OptimizationFunction(f, AutoForwardDiff(); kwargs...)\u001b[39m\n",
       "\n",
       "  This uses the ForwardDiff.jl (https://github.com/JuliaDiff/ForwardDiff.jl)\n",
       "  package. It is the fastest choice for small systems, especially with heavy\n",
       "  scalar interactions. It is easy to use and compatible with most Julia\n",
       "  functions which have loose type restrictions. However, because it's\n",
       "  forward-mode, it scales poorly in comparison to other AD choices. Hessian\n",
       "  construction is suboptimal as it uses the forward-over-forward approach.\n",
       "\n",
       "    •  Compatible with GPUs\n",
       "\n",
       "    •  Compatible with Hessian-based optimization\n",
       "\n",
       "    •  Compatible with Hv-based optimization\n",
       "\n",
       "    •  Compatible with constraints\n",
       "\n",
       "  Note that only the unspecified derivative functions are defined. For\n",
       "  example, if a \u001b[36mhess\u001b[39m function is supplied to the \u001b[36mOptimizationFunction\u001b[39m, then\n",
       "  the Hessian is not defined via ForwardDiff."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?AutoForwardDiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e632607-db7f-4a9c-9f5f-b11e8c23f019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the objective function\n",
    "f(x, y) = x^2 + 3y^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58875be8-811c-4f9e-98e4-1183d74e2542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "obj (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the optimization problem\n",
    "function obj(u, p) # p is unused but necessary for the next step where obj is called for OptimizationFunction\n",
    "    x, y = u\n",
    "    return f(x, y)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a3cfd27-3184-40f7-893e-ad046e2ba506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(::OptimizationFunction{true, AutoForwardDiff{nothing, Nothing}, typeof(obj), Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, typeof(SciMLBase.DEFAULT_OBSERVED_NO_TIME), Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing, Nothing}) (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0 = [3.0, 2.0]  # Starting point\n",
    "optf = OptimizationFunction(obj, AutoForwardDiff()) # specify how descent is calculated with AutoForwardDiff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1326b91-20fb-405a-8d81-2739420e27f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93a2e335-e84d-44d7-9f70-4178c7335edd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[38;2;86;182;194mOptimizationProblem\u001b[0m. In-place: \u001b[38;2;86;182;194mtrue\u001b[0m\n",
       "u0: 2-element Vector{Float64}:\n",
       " 3.0\n",
       " 2.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the optimization problem\n",
    "prob = OptimizationProblem(optf, x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52ce3c30-c36c-483e-b9f5-5005835aabab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1mG\u001b[22m\u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1md\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1mD\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1mt\u001b[22m \u001b[0m\u001b[1mG\u001b[22m\u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1md\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1mD\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1mt\u001b[22mState \u001b[0m\u001b[1mG\u001b[22m\u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1md\u001b[22m\u001b[0m\u001b[1mi\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1mD\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1mt\u001b[22mOptimizer\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\section{Gradient Descent}\n",
       "\\subsection{Constructor}\n",
       "\\begin{verbatim}\n",
       "GradientDescent(; alphaguess = LineSearches.InitialHagerZhang(),\n",
       "linesearch = LineSearches.HagerZhang(),\n",
       "P = nothing,\n",
       "precondprep = (P, x) -> nothing)\n",
       "\\end{verbatim}\n",
       "Keywords are used to control choice of line search, and preconditioning.\n",
       "\n",
       "\\subsection{Description}\n",
       "The \\texttt{GradientDescent} method is a simple gradient descent algorithm, that is the search direction is simply the negative gradient at the current iterate, and then a line search step is used to compute the final step. See Nocedal and Wright (ch. 2.2, 1999) for an explanation of the approach.\n",
       "\n",
       "\\subsection{References}\n",
       "\\begin{itemize}\n",
       "\\item Nocedal, J. and Wright, S. J. (1999), Numerical optimization. Springer Science 35.67-68: 7.\n",
       "\n",
       "\\end{itemize}\n"
      ],
      "text/markdown": [
       "# Gradient Descent\n",
       "\n",
       "## Constructor\n",
       "\n",
       "```julia\n",
       "GradientDescent(; alphaguess = LineSearches.InitialHagerZhang(),\n",
       "linesearch = LineSearches.HagerZhang(),\n",
       "P = nothing,\n",
       "precondprep = (P, x) -> nothing)\n",
       "```\n",
       "\n",
       "Keywords are used to control choice of line search, and preconditioning.\n",
       "\n",
       "## Description\n",
       "\n",
       "The `GradientDescent` method is a simple gradient descent algorithm, that is the search direction is simply the negative gradient at the current iterate, and then a line search step is used to compute the final step. See Nocedal and Wright (ch. 2.2, 1999) for an explanation of the approach.\n",
       "\n",
       "## References\n",
       "\n",
       "  * Nocedal, J. and Wright, S. J. (1999), Numerical optimization. Springer Science 35.67-68: 7.\n"
      ],
      "text/plain": [
       "\u001b[1m  Gradient Descent\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "\u001b[1m  Constructor\u001b[22m\n",
       "\u001b[1m  ===========\u001b[22m\n",
       "\n",
       "\u001b[36m  GradientDescent(; alphaguess = LineSearches.InitialHagerZhang(),\u001b[39m\n",
       "\u001b[36m  linesearch = LineSearches.HagerZhang(),\u001b[39m\n",
       "\u001b[36m  P = nothing,\u001b[39m\n",
       "\u001b[36m  precondprep = (P, x) -> nothing)\u001b[39m\n",
       "\n",
       "  Keywords are used to control choice of line search, and preconditioning.\n",
       "\n",
       "\u001b[1m  Description\u001b[22m\n",
       "\u001b[1m  ===========\u001b[22m\n",
       "\n",
       "  The \u001b[36mGradientDescent\u001b[39m method is a simple gradient descent algorithm, that is\n",
       "  the search direction is simply the negative gradient at the current iterate,\n",
       "  and then a line search step is used to compute the final step. See Nocedal\n",
       "  and Wright (ch. 2.2, 1999) for an explanation of the approach.\n",
       "\n",
       "\u001b[1m  References\u001b[22m\n",
       "\u001b[1m  ==========\u001b[22m\n",
       "\n",
       "    •  Nocedal, J. and Wright, S. J. (1999), Numerical optimization.\n",
       "       Springer Science 35.67-68: 7."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?GradientDescent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3c42710-fbfd-4ad8-bd74-2ddf7c9ce1a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "retcode: Success\n",
       "u: 2-element Vector{Float64}:\n",
       "  1.6114282515494203e-9\n",
       " -2.685713752582376e-10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solve the problem using gradient descent\n",
    "sol = solve(prob, GradientDescent(), maxiters=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21fc2182-0002-48ec-895c-d86c740ea79a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1ml\u001b[22m\u001b[0m\u001b[1mv\u001b[22m\u001b[0m\u001b[1me\u001b[22m \u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1ml\u001b[22m\u001b[0m\u001b[1mv\u001b[22m\u001b[0m\u001b[1me\u001b[22m! i\u001b[0m\u001b[1ms\u001b[22ms\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1ml\u001b[22m\u001b[0m\u001b[1mv\u001b[22m\u001b[0m\u001b[1me\u001b[22mrstepclock get_\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1ml\u001b[22m\u001b[0m\u001b[1mv\u001b[22m\u001b[0m\u001b[1me\u001b[22mr_result Debug\u001b[0m\u001b[1mS\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1ml\u001b[22m\u001b[0m\u001b[1mv\u001b[22m\u001b[0m\u001b[1me\u001b[22mrState\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "CommonSolve.solve(args...; kwargs...)\n",
       "\\end{verbatim}\n",
       "Solves an equation or other mathematical problem using the algorithm specified in the arguments. Generally, the interface is:\n",
       "\n",
       "\\begin{verbatim}\n",
       "CommonSolve.solve(prob::ProblemType,alg::SolverType; kwargs...)::SolutionType\n",
       "\\end{verbatim}\n",
       "where the keyword arguments are uniform across all choices of algorithms.\n",
       "\n",
       "By default, \\texttt{solve} defaults to using \\texttt{solve!} on the iterator form, i.e.:\n",
       "\n",
       "\\begin{verbatim}\n",
       "solve(args...; kwargs...) = solve!(init(args...; kwargs...))\n",
       "\\end{verbatim}\n",
       "\\rule{\\textwidth}{1pt}\n",
       "\\begin{verbatim}\n",
       "solve(prob::OptimizationProblem, alg::AbstractOptimizationAlgorithm, args...; kwargs...)\n",
       "\\end{verbatim}\n",
       "\\subsection{Keyword Arguments}\n",
       "The arguments to \\texttt{solve} are common across all of the optimizers. These common arguments are:\n",
       "\n",
       "\\begin{itemize}\n",
       "\\item \\texttt{maxiters}: the maximum number of iterations\n",
       "\n",
       "\n",
       "\\item \\texttt{maxtime}: the maximum amount of time (typically in seconds) the optimization runs for\n",
       "\n",
       "\n",
       "\\item \\texttt{abstol}: absolute tolerance in changes of the objective value\n",
       "\n",
       "\n",
       "\\item \\texttt{reltol}: relative tolerance  in changes of the objective value\n",
       "\n",
       "\n",
       "\\item \\texttt{callback}: a callback function\n",
       "\n",
       "\\end{itemize}\n",
       "Some optimizer algorithms have special keyword arguments documented in the solver portion of the documentation and their respective documentation. These arguments can be passed as \\texttt{kwargs...} to \\texttt{solve}. Similarly, the special keyword arguments for the \\texttt{local\\_method} of a global optimizer are passed as a \\texttt{NamedTuple} to \\texttt{local\\_options}.\n",
       "\n",
       "Over time, we hope to cover more of these keyword arguments under the common interface.\n",
       "\n",
       "If a common argument is not implemented for a optimizer, a warning will be shown.\n",
       "\n",
       "\\subsection{Callback Functions}\n",
       "The callback function \\texttt{callback} is a function which is called after every optimizer step. Its signature is:\n",
       "\n",
       "\\begin{verbatim}\n",
       "callback = (state, loss_val) -> false\n",
       "\\end{verbatim}\n",
       "where \\texttt{state} is a \\texttt{OptimizationState} and stores information for the current iteration of the solver and \\texttt{loss\\_val} is loss/objective value. For more information about the fields of the \\texttt{state} look at the \\texttt{OptimizationState} documentation. The callback should return a Boolean value, and the default should be \\texttt{false}, such that the optimization gets stopped if it returns \\texttt{true}.\n",
       "\n",
       "\\subsubsection{Callback Example}\n",
       "Here we show an example a callback function that plots the prediction at the current value of the optimization variables. The loss function here returns the loss and the prediction i.e. the solution of the \\texttt{ODEProblem} \\texttt{prob}, so we can use the prediction in the callback.\n",
       "\n",
       "\\begin{verbatim}\n",
       "function predict(u)\n",
       "    Array(solve(prob, Tsit5(), p = u))\n",
       "end\n",
       "\n",
       "function loss(u, p)\n",
       "    pred = predict(u)\n",
       "    sum(abs2, batch .- pred), pred\n",
       "end\n",
       "\n",
       "callback = function (state, l; doplot = false) #callback function to observe training\n",
       "    display(l)\n",
       "    # plot current prediction against data\n",
       "    if doplot\n",
       "        pred = predict(state.u)\n",
       "        pl = scatter(t, ode_data[1, :], label = \"data\")\n",
       "        scatter!(pl, t, pred[1, :], label = \"prediction\")\n",
       "        display(plot(pl))\n",
       "    end\n",
       "    return false\n",
       "end\n",
       "\\end{verbatim}\n",
       "If the chosen method is a global optimizer that employs a local optimization method, a similar set of common local optimizer arguments exists. Look at \\texttt{MLSL} or \\texttt{AUGLAG} from NLopt for an example. The common local optimizer arguments are:\n",
       "\n",
       "\\begin{itemize}\n",
       "\\item \\texttt{local\\_method}: optimizer used for local optimization in global method\n",
       "\n",
       "\n",
       "\\item \\texttt{local\\_maxiters}: the maximum number of iterations\n",
       "\n",
       "\n",
       "\\item \\texttt{local\\_maxtime}: the maximum amount of time (in seconds) the optimization runs for\n",
       "\n",
       "\n",
       "\\item \\texttt{local\\_abstol}: absolute tolerance in changes of the objective value\n",
       "\n",
       "\n",
       "\\item \\texttt{local\\_reltol}: relative tolerance  in changes of the objective value\n",
       "\n",
       "\n",
       "\\item \\texttt{local\\_options}: \\texttt{NamedTuple} of keyword arguments for local optimizer\n",
       "\n",
       "\\end{itemize}\n"
      ],
      "text/markdown": [
       "```julia\n",
       "CommonSolve.solve(args...; kwargs...)\n",
       "```\n",
       "\n",
       "Solves an equation or other mathematical problem using the algorithm specified in the arguments. Generally, the interface is:\n",
       "\n",
       "```julia\n",
       "CommonSolve.solve(prob::ProblemType,alg::SolverType; kwargs...)::SolutionType\n",
       "```\n",
       "\n",
       "where the keyword arguments are uniform across all choices of algorithms.\n",
       "\n",
       "By default, `solve` defaults to using `solve!` on the iterator form, i.e.:\n",
       "\n",
       "```julia\n",
       "solve(args...; kwargs...) = solve!(init(args...; kwargs...))\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "```julia\n",
       "solve(prob::OptimizationProblem, alg::AbstractOptimizationAlgorithm, args...; kwargs...)\n",
       "```\n",
       "\n",
       "## Keyword Arguments\n",
       "\n",
       "The arguments to `solve` are common across all of the optimizers. These common arguments are:\n",
       "\n",
       "  * `maxiters`: the maximum number of iterations\n",
       "  * `maxtime`: the maximum amount of time (typically in seconds) the optimization runs for\n",
       "  * `abstol`: absolute tolerance in changes of the objective value\n",
       "  * `reltol`: relative tolerance  in changes of the objective value\n",
       "  * `callback`: a callback function\n",
       "\n",
       "Some optimizer algorithms have special keyword arguments documented in the solver portion of the documentation and their respective documentation. These arguments can be passed as `kwargs...` to `solve`. Similarly, the special keyword arguments for the `local_method` of a global optimizer are passed as a `NamedTuple` to `local_options`.\n",
       "\n",
       "Over time, we hope to cover more of these keyword arguments under the common interface.\n",
       "\n",
       "If a common argument is not implemented for a optimizer, a warning will be shown.\n",
       "\n",
       "## Callback Functions\n",
       "\n",
       "The callback function `callback` is a function which is called after every optimizer step. Its signature is:\n",
       "\n",
       "```julia\n",
       "callback = (state, loss_val) -> false\n",
       "```\n",
       "\n",
       "where `state` is a `OptimizationState` and stores information for the current iteration of the solver and `loss_val` is loss/objective value. For more information about the fields of the `state` look at the `OptimizationState` documentation. The callback should return a Boolean value, and the default should be `false`, such that the optimization gets stopped if it returns `true`.\n",
       "\n",
       "### Callback Example\n",
       "\n",
       "Here we show an example a callback function that plots the prediction at the current value of the optimization variables. The loss function here returns the loss and the prediction i.e. the solution of the `ODEProblem` `prob`, so we can use the prediction in the callback.\n",
       "\n",
       "```julia\n",
       "function predict(u)\n",
       "    Array(solve(prob, Tsit5(), p = u))\n",
       "end\n",
       "\n",
       "function loss(u, p)\n",
       "    pred = predict(u)\n",
       "    sum(abs2, batch .- pred), pred\n",
       "end\n",
       "\n",
       "callback = function (state, l; doplot = false) #callback function to observe training\n",
       "    display(l)\n",
       "    # plot current prediction against data\n",
       "    if doplot\n",
       "        pred = predict(state.u)\n",
       "        pl = scatter(t, ode_data[1, :], label = \"data\")\n",
       "        scatter!(pl, t, pred[1, :], label = \"prediction\")\n",
       "        display(plot(pl))\n",
       "    end\n",
       "    return false\n",
       "end\n",
       "```\n",
       "\n",
       "If the chosen method is a global optimizer that employs a local optimization method, a similar set of common local optimizer arguments exists. Look at `MLSL` or `AUGLAG` from NLopt for an example. The common local optimizer arguments are:\n",
       "\n",
       "  * `local_method`: optimizer used for local optimization in global method\n",
       "  * `local_maxiters`: the maximum number of iterations\n",
       "  * `local_maxtime`: the maximum amount of time (in seconds) the optimization runs for\n",
       "  * `local_abstol`: absolute tolerance in changes of the objective value\n",
       "  * `local_reltol`: relative tolerance  in changes of the objective value\n",
       "  * `local_options`: `NamedTuple` of keyword arguments for local optimizer\n"
      ],
      "text/plain": [
       "\u001b[36m  CommonSolve.solve(args...; kwargs...)\u001b[39m\n",
       "\n",
       "  Solves an equation or other mathematical problem using the algorithm\n",
       "  specified in the arguments. Generally, the interface is:\n",
       "\n",
       "\u001b[36m  CommonSolve.solve(prob::ProblemType,alg::SolverType; kwargs...)::SolutionType\u001b[39m\n",
       "\n",
       "  where the keyword arguments are uniform across all choices of algorithms.\n",
       "\n",
       "  By default, \u001b[36msolve\u001b[39m defaults to using \u001b[36msolve!\u001b[39m on the iterator form, i.e.:\n",
       "\n",
       "\u001b[36m  solve(args...; kwargs...) = solve!(init(args...; kwargs...))\u001b[39m\n",
       "\n",
       "  ────────────────────────────────────────────────────────────────────────────\n",
       "\n",
       "\u001b[36m  solve(prob::OptimizationProblem, alg::AbstractOptimizationAlgorithm, args...; kwargs...)\u001b[39m\n",
       "\n",
       "\u001b[1m  Keyword Arguments\u001b[22m\n",
       "\u001b[1m  =================\u001b[22m\n",
       "\n",
       "  The arguments to \u001b[36msolve\u001b[39m are common across all of the optimizers. These common\n",
       "  arguments are:\n",
       "\n",
       "    •  \u001b[36mmaxiters\u001b[39m: the maximum number of iterations\n",
       "\n",
       "    •  \u001b[36mmaxtime\u001b[39m: the maximum amount of time (typically in seconds) the\n",
       "       optimization runs for\n",
       "\n",
       "    •  \u001b[36mabstol\u001b[39m: absolute tolerance in changes of the objective value\n",
       "\n",
       "    •  \u001b[36mreltol\u001b[39m: relative tolerance in changes of the objective value\n",
       "\n",
       "    •  \u001b[36mcallback\u001b[39m: a callback function\n",
       "\n",
       "  Some optimizer algorithms have special keyword arguments documented in the\n",
       "  solver portion of the documentation and their respective documentation.\n",
       "  These arguments can be passed as \u001b[36mkwargs...\u001b[39m to \u001b[36msolve\u001b[39m. Similarly, the special\n",
       "  keyword arguments for the \u001b[36mlocal_method\u001b[39m of a global optimizer are passed as a\n",
       "  \u001b[36mNamedTuple\u001b[39m to \u001b[36mlocal_options\u001b[39m.\n",
       "\n",
       "  Over time, we hope to cover more of these keyword arguments under the common\n",
       "  interface.\n",
       "\n",
       "  If a common argument is not implemented for a optimizer, a warning will be\n",
       "  shown.\n",
       "\n",
       "\u001b[1m  Callback Functions\u001b[22m\n",
       "\u001b[1m  ==================\u001b[22m\n",
       "\n",
       "  The callback function \u001b[36mcallback\u001b[39m is a function which is called after every\n",
       "  optimizer step. Its signature is:\n",
       "\n",
       "\u001b[36m  callback = (state, loss_val) -> false\u001b[39m\n",
       "\n",
       "  where \u001b[36mstate\u001b[39m is a \u001b[36mOptimizationState\u001b[39m and stores information for the current\n",
       "  iteration of the solver and \u001b[36mloss_val\u001b[39m is loss/objective value. For more\n",
       "  information about the fields of the \u001b[36mstate\u001b[39m look at the \u001b[36mOptimizationState\u001b[39m\n",
       "  documentation. The callback should return a Boolean value, and the default\n",
       "  should be \u001b[36mfalse\u001b[39m, such that the optimization gets stopped if it returns \u001b[36mtrue\u001b[39m.\n",
       "\n",
       "\u001b[1m  Callback Example\u001b[22m\n",
       "\u001b[1m  ––––––––––––––––\u001b[22m\n",
       "\n",
       "  Here we show an example a callback function that plots the prediction at the\n",
       "  current value of the optimization variables. The loss function here returns\n",
       "  the loss and the prediction i.e. the solution of the \u001b[36mODEProblem\u001b[39m \u001b[36mprob\u001b[39m, so we\n",
       "  can use the prediction in the callback.\n",
       "\n",
       "\u001b[36m  function predict(u)\u001b[39m\n",
       "\u001b[36m      Array(solve(prob, Tsit5(), p = u))\u001b[39m\n",
       "\u001b[36m  end\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  function loss(u, p)\u001b[39m\n",
       "\u001b[36m      pred = predict(u)\u001b[39m\n",
       "\u001b[36m      sum(abs2, batch .- pred), pred\u001b[39m\n",
       "\u001b[36m  end\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  callback = function (state, l; doplot = false) #callback function to observe training\u001b[39m\n",
       "\u001b[36m      display(l)\u001b[39m\n",
       "\u001b[36m      # plot current prediction against data\u001b[39m\n",
       "\u001b[36m      if doplot\u001b[39m\n",
       "\u001b[36m          pred = predict(state.u)\u001b[39m\n",
       "\u001b[36m          pl = scatter(t, ode_data[1, :], label = \"data\")\u001b[39m\n",
       "\u001b[36m          scatter!(pl, t, pred[1, :], label = \"prediction\")\u001b[39m\n",
       "\u001b[36m          display(plot(pl))\u001b[39m\n",
       "\u001b[36m      end\u001b[39m\n",
       "\u001b[36m      return false\u001b[39m\n",
       "\u001b[36m  end\u001b[39m\n",
       "\n",
       "  If the chosen method is a global optimizer that employs a local optimization\n",
       "  method, a similar set of common local optimizer arguments exists. Look at\n",
       "  \u001b[36mMLSL\u001b[39m or \u001b[36mAUGLAG\u001b[39m from NLopt for an example. The common local optimizer\n",
       "  arguments are:\n",
       "\n",
       "    •  \u001b[36mlocal_method\u001b[39m: optimizer used for local optimization in global\n",
       "       method\n",
       "\n",
       "    •  \u001b[36mlocal_maxiters\u001b[39m: the maximum number of iterations\n",
       "\n",
       "    •  \u001b[36mlocal_maxtime\u001b[39m: the maximum amount of time (in seconds) the\n",
       "       optimization runs for\n",
       "\n",
       "    •  \u001b[36mlocal_abstol\u001b[39m: absolute tolerance in changes of the objective value\n",
       "\n",
       "    •  \u001b[36mlocal_reltol\u001b[39m: relative tolerance in changes of the objective value\n",
       "\n",
       "    •  \u001b[36mlocal_options\u001b[39m: \u001b[36mNamedTuple\u001b[39m of keyword arguments for local optimizer"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d26a036d-7992-4aa9-bc33-bd8dc6fff0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x0[1], x0[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4449796d-9fd3-448b-a939-c8a921890bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5901de65-5c20-4214-a53c-23149fa4dad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_objective = f(x0...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe5e1f4-5ee8-4c91-a233-b13db2178be3",
   "metadata": {},
   "source": [
    "The ... operator in Julia is called the \"splat\" operator. It's used to \"unpack\" or \"spread\" the elements of an array or tuple into individual arguments for a function call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30da2171-badb-4d96-9707-8e8c501a9a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cb (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function cb(state, flag)\n",
    "    global prev_objective  # Use the global variable\n",
    "    \n",
    "    current_u = state.u\n",
    "    current_objective = state.objective\n",
    "\n",
    "    # Calculate the difference in objective value\n",
    "    obj_difference = current_objective - prev_objective\n",
    "    \n",
    "    println(\"Iteration: $(state.iter)\")\n",
    "    println(\"Current point: x = $(current_u[1]), y = $(current_u[2])\")\n",
    "    println(\"Current f(x,y) = $current_objective\")\n",
    "    println(\"Difference from last iteration: $obj_difference\")\n",
    "    println(\"---\")\n",
    "\n",
    "    prev_objective = current_objective\n",
    "\n",
    "    return false # continue optimization \n",
    "    # should be able to do something like return obj_difference < 1e-6, but seems AutoForwardDiff (or other part?) also takes care of where to stop\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20a40ecd-6f20-4e82-be4c-bb9149e3eb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Current point: x = 3.0, y = 2.0\n",
      "Current f(x,y) = 21.0\n",
      "Difference from last iteration: 0.0\n",
      "---\n",
      "Iteration: 1\n",
      "Current point: x = 1.846153846153846, y = -0.30769230769230793\n",
      "Current f(x,y) = 3.6923076923076925\n",
      "Difference from last iteration: -17.307692307692307\n",
      "---\n",
      "Iteration: 2\n",
      "Current point: x = 0.527472527472528, y = 0.3516483516483516\n",
      "Current f(x,y) = 0.6491969568892652\n",
      "Difference from last iteration: -3.0431107354184275\n",
      "---\n",
      "Iteration: 3\n",
      "Current point: x = 0.3245984784446326, y = -0.05409974640743881\n",
      "Current f(x,y) = 0.11414451989261816\n",
      "Difference from last iteration: -0.535052436996647\n",
      "---\n",
      "Iteration: 4\n",
      "Current point: x = 0.09274242241275227, y = 0.06182828160850144\n",
      "Current f(x,y) = 0.02006936613496585\n",
      "Difference from last iteration: -0.09407515375765231\n",
      "---\n",
      "Iteration: 5\n",
      "Current point: x = 0.05707225994630907, y = -0.00951204332438485\n",
      "Current f(x,y) = 0.003528679759993998\n",
      "Difference from last iteration: -0.01654068637497185\n",
      "---\n",
      "Iteration: 6\n",
      "Current point: x = 0.016306359984659742, y = 0.010870906656439826\n",
      "Current f(x,y) = 0.0006204272105483956\n",
      "Difference from last iteration: -0.002908252549445603\n",
      "---\n",
      "Iteration: 7\n",
      "Current point: x = 0.010034683067482918, y = -0.0016724471779138213\n",
      "Current f(x,y) = 0.0001090861029535641\n",
      "Difference from last iteration: -0.0005113411075948315\n",
      "---\n",
      "Iteration: 8\n",
      "Current point: x = 0.002867052304995122, y = 0.0019113682033300799\n",
      "Current f(x,y) = 1.9179974145681615e-5\n",
      "Difference from last iteration: -8.990612880788248e-5\n",
      "---\n",
      "Iteration: 9\n",
      "Current point: x = 0.001764339879996998, y = -0.0002940566466661668\n",
      "Current f(x,y) = 3.372303146493474e-6\n",
      "Difference from last iteration: -1.580767099918814e-5\n",
      "---\n",
      "Iteration: 10\n",
      "Current point: x = 0.000504097108570572, y = 0.00033606473904704715\n",
      "Current f(x,y) = 5.929324213614908e-7\n",
      "Difference from last iteration: -2.779370725131983e-6\n",
      "---\n",
      "Iteration: 11\n",
      "Current point: x = 0.00031021360527419805, y = -5.170226754569983e-5\n",
      "Current f(x,y) = 1.0425185430531734e-7\n",
      "Difference from last iteration: -4.886805670561735e-7\n",
      "---\n",
      "Iteration: 12\n",
      "Current point: x = 8.863245864977121e-5, y = 5.9088305766513916e-5\n",
      "Current f(x,y) = 1.8329996361374528e-8\n",
      "Difference from last iteration: -8.592185794394281e-8\n",
      "---\n",
      "Iteration: 13\n",
      "Current point: x = 5.454305147678226e-5, y = -9.090508579463736e-6\n",
      "Current f(x,y) = 3.2228565030988306e-9\n",
      "Difference from last iteration: -1.5107139858275697e-8\n",
      "---\n",
      "Iteration: 14\n",
      "Current point: x = 1.5583728993366415e-5, y = 1.0389152662244244e-5\n",
      "Current f(x,y) = 5.66656088456939e-10\n",
      "Difference from last iteration: -2.656200414641892e-9\n",
      "---\n",
      "Iteration: 15\n",
      "Current point: x = 9.589987072840868e-6, y = -1.598331178806813e-6\n",
      "Current f(x,y) = 9.96318397286929e-11\n",
      "Difference from last iteration: -4.67024248728246e-10\n",
      "---\n",
      "Iteration: 16\n",
      "Current point: x = 2.7399963065259668e-6, y = 1.8266642043506415e-6\n",
      "Current f(x,y) = 1.7517686106143826e-11\n",
      "Difference from last iteration: -8.211415362254908e-11\n",
      "---\n",
      "Iteration: 17\n",
      "Current point: x = 1.6861515732467484e-6, y = -2.810252622077919e-7\n",
      "Current f(x,y) = 3.0800327219593593e-12\n",
      "Difference from last iteration: -1.4437653384184467e-11\n",
      "---\n",
      "Iteration: 18\n",
      "Current point: x = 4.817575923562147e-7, y = 3.21171728237476e-7\n",
      "Current f(x,y) = 5.415442148499981e-13\n",
      "Difference from last iteration: -2.5384885071093613e-12\n",
      "---\n",
      "Iteration: 19\n",
      "Current point: x = 2.9646621068074743e-7, y = -4.941103511345801e-8\n",
      "Current f(x,y) = 9.521656524835145e-14\n",
      "Difference from last iteration: -4.463276496016467e-13\n",
      "---\n",
      "Iteration: 20\n",
      "Current point: x = 8.47046316230709e-8, y = 5.6469754415380494e-8\n",
      "Current f(x,y) = 1.67413741096003e-14\n",
      "Difference from last iteration: -7.847519113875115e-14\n",
      "---\n",
      "Iteration: 21\n",
      "Current point: x = 5.2125927152659e-8, y = -8.687654525443184e-9\n",
      "Current f(x,y) = 2.9435383049846732e-15\n",
      "Difference from last iteration: -1.3797835804615627e-14\n",
      "---\n",
      "Iteration: 22\n",
      "Current point: x = 1.4893122043616889e-8, y = 9.928748029077911e-9\n",
      "Current f(x,y) = 5.175451964808228e-16\n",
      "Difference from last iteration: -2.4259931085038504e-15\n",
      "---\n",
      "Iteration: 23\n",
      "Current point: x = 9.164998180687314e-9, y = -1.5274996967812217e-9\n",
      "Current f(x,y) = 9.099695762300195e-17\n",
      "Difference from last iteration: -4.265482388578209e-16\n",
      "---\n",
      "Iteration: 24\n",
      "Current point: x = 2.618570908767809e-9, y = 1.7457139391785368e-9\n",
      "Current f(x,y) = 1.5999465076571803e-17\n",
      "Difference from last iteration: -7.499749254643014e-17\n",
      "---\n",
      "Iteration: 25\n",
      "Current point: x = 1.6114282515494203e-9, y = -2.685713752582376e-10\n",
      "Current f(x,y) = 2.813092760715925e-18\n",
      "Difference from last iteration: -1.3186372315855878e-17\n",
      "---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "retcode: Success\n",
       "u: 2-element Vector{Float64}:\n",
       "  1.6114282515494203e-9\n",
       " -2.685713752582376e-10"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function cb(state, flag)\n",
    "#     current_u = state.u\n",
    "#     current_f_value = state.objective\n",
    "#     println(\"Current point: x = $(current_u[1]), y = $(current_u[2])\")\n",
    "#     println(\"Current f(x,y) = $current_f_value\")\n",
    "#     return false # continue optimization\n",
    "# end\n",
    "\n",
    "# Solve the problem\n",
    "sol = solve(prob, GradientDescent(), maxiters=100, callback=cb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f845c870-eca3-47b4-a357-a9d308c95b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Current point: x = 3.0, y = 2.0\n",
      "Current f(x,y) = 21.0\n",
      "Difference from last iteration: 21.0\n",
      "---\n",
      "Iteration: 1\n",
      "Current point: x = 1.846153846153846, y = -0.30769230769230793\n",
      "Current f(x,y) = 3.6923076923076925\n",
      "Difference from last iteration: -17.307692307692307\n",
      "---\n",
      "Iteration: 2\n",
      "Current point: x = 0.527472527472528, y = 0.3516483516483516\n",
      "Current f(x,y) = 0.6491969568892652\n",
      "Difference from last iteration: -3.0431107354184275\n",
      "---\n",
      "Iteration: 3\n",
      "Current point: x = 0.3245984784446326, y = -0.05409974640743881\n",
      "Current f(x,y) = 0.11414451989261816\n",
      "Difference from last iteration: -0.535052436996647\n",
      "---\n",
      "Iteration: 4\n",
      "Current point: x = 0.09274242241275227, y = 0.06182828160850144\n",
      "Current f(x,y) = 0.02006936613496585\n",
      "Difference from last iteration: -0.09407515375765231\n",
      "---\n",
      "Iteration: 5\n",
      "Current point: x = 0.05707225994630907, y = -0.00951204332438485\n",
      "Current f(x,y) = 0.003528679759993998\n",
      "Difference from last iteration: -0.01654068637497185\n",
      "---\n",
      "Iteration: 6\n",
      "Current point: x = 0.016306359984659742, y = 0.010870906656439826\n",
      "Current f(x,y) = 0.0006204272105483956\n",
      "Difference from last iteration: -0.002908252549445603\n",
      "---\n",
      "Iteration: 7\n",
      "Current point: x = 0.010034683067482918, y = -0.0016724471779138213\n",
      "Current f(x,y) = 0.0001090861029535641\n",
      "Difference from last iteration: -0.0005113411075948315\n",
      "---\n",
      "Iteration: 8\n",
      "Current point: x = 0.002867052304995122, y = 0.0019113682033300799\n",
      "Current f(x,y) = 1.9179974145681615e-5\n",
      "Difference from last iteration: -8.990612880788248e-5\n",
      "---\n",
      "Iteration: 9\n",
      "Current point: x = 0.001764339879996998, y = -0.0002940566466661668\n",
      "Current f(x,y) = 3.372303146493474e-6\n",
      "Difference from last iteration: -1.580767099918814e-5\n",
      "---\n",
      "Iteration: 10\n",
      "Current point: x = 0.000504097108570572, y = 0.00033606473904704715\n",
      "Current f(x,y) = 5.929324213614908e-7\n",
      "Difference from last iteration: -2.779370725131983e-6\n",
      "---\n",
      "Iteration: 11\n",
      "Current point: x = 0.00031021360527419805, y = -5.170226754569983e-5\n",
      "Current f(x,y) = 1.0425185430531734e-7\n",
      "Difference from last iteration: -4.886805670561735e-7\n",
      "---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "retcode: Failure\n",
       "u: 2-element Vector{Float64}:\n",
       "  0.00031021360527419805\n",
       " -5.170226754569983e-5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function cb_try(state, flag)\n",
    "    global prev_objective  # Use the global variable\n",
    "    \n",
    "    current_u = state.u\n",
    "    current_objective = state.objective\n",
    "\n",
    "    # Calculate the difference in objective value\n",
    "    obj_difference = current_objective - prev_objective\n",
    "    \n",
    "    println(\"Iteration: $(state.iter)\")\n",
    "    println(\"Current point: x = $(current_u[1]), y = $(current_u[2])\")\n",
    "    println(\"Current f(x,y) = $current_objective\")\n",
    "    println(\"Difference from last iteration: $obj_difference\")\n",
    "    println(\"---\")\n",
    "\n",
    "    prev_objective = current_objective\n",
    "\n",
    "    return abs(obj_difference)<1e-6 # continue optimization \n",
    "    # should be able to do something like return obj_difference < 1e-6, but seems AutoForwardDiff (or other part?) also takes care of where to stop\n",
    "end\n",
    "\n",
    "sol_try = solve(prob, GradientDescent(), maxiters=100, callback=cb_try) # retcode: Failure -- conflication with optimization setting I guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbebbc7e-445e-4536-921b-cc5cf6f407fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
